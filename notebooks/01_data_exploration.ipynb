{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "## Assignment Task 1: Dataset Summary\n",
    "## Assignment Task 2: Data Exploration Plan\n",
    "\n",
    "This notebook covers the initial exploration of the dataset, including:\n",
    "- Loading and examining the dataset\n",
    "- Creating a comprehensive dataset summary\n",
    "- Developing a data exploration plan\n",
    "- Initial data quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from data.data_loader import DataLoader\n",
    "from analysis.eda import ExploratoryDataAnalysis\n",
    "from visualization.plots import DataVisualizer\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader('../data/raw')\n",
    "\n",
    "# Load dataset (replace 'your_dataset.csv' with actual filename)\n",
    "try:\n",
    "    # Example: loader.load_dataset('your_dataset.csv')\n",
    "    print(\"Please load your dataset using loader.load_dataset('filename.csv')\")\n",
    "    print(\"Supported formats: CSV, Excel, JSON\")\n",
    "    \n",
    "    # For demonstration, let's create a sample dataset\n",
    "    sample_data = {\n",
    "        'id': range(1, 1001),\n",
    "        'age': np.random.normal(35, 10, 1000),\n",
    "        'income': np.random.lognormal(10, 1, 1000),\n",
    "        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], 1000),\n",
    "        'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], 1000),\n",
    "        'target': np.random.choice([0, 1], 1000, p=[0.7, 0.3])\n",
    "    }\n",
    "    \n",
    "    dataset = pd.DataFrame(sample_data)\n",
    "    loader.dataset = dataset\n",
    "    loader._extract_dataset_info()\n",
    "    \n",
    "    print(\"Sample dataset created for demonstration purposes.\")\n",
    "    print(\"Replace this with your actual dataset loading.\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Dataset not found: {e}\")\n",
    "    print(\"Please ensure your dataset is in the data/raw directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Summary (Task 1)\n",
    "\n",
    "Creating a comprehensive summary of the dataset including size, variables, and potential target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset summary\n",
    "dataset_summary = loader.get_dataset_summary()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset Size: {dataset_summary['dataset_size']}\")\n",
    "print(f\"Memory Usage: {dataset_summary['memory_usage']}\")\n",
    "print(f\"Numeric Variables: {dataset_summary['numeric_variables']}\")\n",
    "print(f\"Categorical Variables: {dataset_summary['categorical_variables']}\")\n",
    "print(f\"Total Missing Values: {dataset_summary['total_missing_values']}\")\n",
    "print()\n",
    "\n",
    "# Display columns information\n",
    "print(\"COLUMNS INFORMATION:\")\n",
    "print(\"-\" * 30)\n",
    "columns_df = pd.DataFrame(dataset_summary['columns_info'])\n",
    "print(columns_df[['name', 'dtype', 'missing_count', 'missing_percentage']].to_string(index=False))\n",
    "\n",
    "# Identify potential target variables\n",
    "target_candidates = loader.identify_target_variables()\n",
    "print(f\"\\nPotential Target Variables: {target_candidates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration Plan (Task 2)\n",
    "\n",
    "Developing a structured exploration plan for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"DATA EXPLORATION PLAN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "1. INITIAL DATA ASSESSMENT\n",
    "   - Dataset size and structure verification\n",
    "   - Data types and memory usage analysis\n",
    "   - Missing data patterns identification\n",
    "   - Duplicate records detection\n",
    "\n",
    "2. UNIVARIATE ANALYSIS\n",
    "   - Distribution analysis of numerical variables\n",
    "   - Frequency analysis of categorical variables\n",
    "   - Identification of outliers and anomalies\n",
    "   - Statistical summary generation\n",
    "\n",
    "3. BIVARIATE ANALYSIS\n",
    "   - Correlation analysis between numerical variables\n",
    "   - Relationship analysis between categorical and numerical variables\n",
    "   - Target variable relationship exploration\n",
    "   - Cross-tabulation of categorical variables\n",
    "\n",
    "4. MULTIVARIATE ANALYSIS\n",
    "   - Multi-dimensional correlation analysis\n",
    "   - Clustering tendency assessment\n",
    "   - Feature interaction identification\n",
    "   - Dimensionality reduction considerations\n",
    "\n",
    "5. DATA QUALITY ASSESSMENT\n",
    "   - Data consistency verification\n",
    "   - Data integrity checks\n",
    "   - Domain knowledge validation\n",
    "   - Business rule compliance verification\n",
    "\n",
    "6. EXPLORATORY VISUALIZATION\n",
    "   - Distribution plots and histograms\n",
    "   - Correlation heatmaps\n",
    "   - Box plots and violin plots\n",
    "   - Scatter plots and pair plots\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EDA class\n",
    "eda = ExploratoryDataAnalysis(loader.dataset)\n",
    "\n",
    "# Analyze missing data\n",
    "missing_data = eda.analyze_missing_data()\n",
    "print(\"MISSING DATA ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "if missing_data.empty:\n",
    "    print(\"No missing data found.\")\n",
    "else:\n",
    "    print(missing_data)\n",
    "\n",
    "# Analyze data types\n",
    "dtypes_analysis = eda.analyze_data_types()\n",
    "print(f\"\\nDATA TYPES ANALYSIS:\")\n",
    "print(\"-\" * 20)\n",
    "print(dtypes_analysis)\n",
    "\n",
    "# Basic statistics\n",
    "basic_stats = eda.get_basic_statistics()\n",
    "print(f\"\\nBASIC STATISTICS:\")\n",
    "print(\"-\" * 17)\n",
    "print(basic_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visual Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = DataVisualizer(loader.dataset)\n",
    "\n",
    "# Plot distributions of numerical variables\n",
    "if visualizer.numeric_columns:\n",
    "    fig1 = visualizer.plot_distribution(figsize=(15, 8))\n",
    "    plt.show()\n",
    "\n",
    "# Plot categorical distributions\n",
    "if visualizer.categorical_columns:\n",
    "    fig2 = visualizer.plot_categorical_distributions(figsize=(15, 8))\n",
    "    plt.show()\n",
    "\n",
    "# Plot correlation matrix\n",
    "if len(visualizer.numeric_columns) > 1:\n",
    "    fig3 = visualizer.plot_correlation_matrix(figsize=(10, 8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"- Dataset loaded successfully with {len(loader.dataset)} rows and {len(loader.dataset.columns)} columns\")\n",
    "print(f\"- Identified {len(visualizer.numeric_columns)} numerical variables\")\n",
    "print(f\"- Identified {len(visualizer.categorical_columns)} categorical variables\")\n",
    "print(f\"- Found {loader.dataset.isnull().sum().sum()} missing values\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"-\" * 12)\n",
    "print(\"1. Proceed to detailed EDA in the next notebook\")\n",
    "print(\"2. Perform data cleaning and preprocessing\")\n",
    "print(\"3. Conduct feature engineering\")\n",
    "print(\"4. Formulate and test hypotheses\")\n",
    "\n",
    "# Generate EDA report\n",
    "eda_report = eda.generate_eda_report()\n",
    "print(f\"\\n{eda_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
