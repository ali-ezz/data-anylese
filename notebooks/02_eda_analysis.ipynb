{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Notebook\n",
    "\n",
    "## Assignment Task 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook covers detailed exploratory data analysis including:\n",
    "- Comprehensive statistical analysis\n",
    "- Advanced visualization techniques\n",
    "- Feature relationship exploration\n",
    "- Outlier detection and analysis\n",
    "- Key insights extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from data.data_loader import DataLoader\n",
    "from analysis.eda import ExploratoryDataAnalysis, AdvancedVisualizations\n",
    "from visualization.plots import DataVisualizer, InteractiveVisualizer\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader('../data/raw')\n",
    "\n",
    "# Load dataset (replace with your actual dataset)\n",
    "try:\n",
    "    # Example: dataset = loader.load_dataset('your_dataset.csv')\n",
    "    print(\"Please load your dataset using loader.load_dataset('filename.csv')\")\n",
    "    print(\"For now, using sample data for demonstration.\")\n",
    "    \n",
    "    # Sample dataset for demonstration\n",
    "    np.random.seed(42)\n",
    "    sample_data = {\n",
    "        'id': range(1, 1001),\n",
    "        'age': np.random.normal(35, 10, 1000),\n",
    "        'income': np.random.lognormal(10, 1, 1000),\n",
    "        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], 1000),\n",
    "        'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], 1000),\n",
    "        'experience': np.random.normal(8, 5, 1000),\n",
    "        'satisfaction': np.random.uniform(1, 10, 1000),\n",
    "        'target': np.random.choice([0, 1], 1000, p=[0.7, 0.3])\n",
    "    }\n",
    "    \n",
    "    # Add some missing values for realism\n",
    "    missing_indices = np.random.choice(1000, 50, replace=False)\n",
    "    for idx in missing_indices[:25]:\n",
    "        sample_data['income'][idx] = np.nan\n",
    "    for idx in missing_indices[25:]:\n",
    "        sample_data['satisfaction'][idx] = np.nan\n",
    "    \n",
    "    dataset = pd.DataFrame(sample_data)\n",
    "    loader.dataset = dataset\n",
    "    loader._extract_dataset_info()\n",
    "    \n",
    "    print(f\"Dataset loaded with {len(dataset)} rows and {len(dataset.columns)} columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize EDA Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EDA components\n",
    "target_column = 'target'  # Specify your target variable\n",
    "eda = ExploratoryDataAnalysis(loader.dataset, target_column)\n",
    "visualizer = DataVisualizer(loader.dataset)\n",
    "interactive_visualizer = InteractiveVisualizer(loader.dataset)\n",
    "\n",
    "print(\"EDA components initialized successfully.\")\n",
    "print(f\"Target variable: {target_column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n1. BASIC STATISTICS\")\n",
    "print(\"-\" * 20)\n",
    "basic_stats = eda.get_basic_statistics()\n",
    "print(basic_stats)\n",
    "\n",
    "# Data types analysis\n",
    "print(\"\\n2. DATA TYPES ANALYSIS\")\n",
    "print(\"-\" * 23)\n",
    "dtypes_analysis = eda.analyze_data_types()\n",
    "print(dtypes_analysis)\n",
    "\n",
    "# Missing data analysis\n",
    "print(\"\\n3. MISSING DATA ANALYSIS\")\n",
    "print(\"-\" * 25)\n",
    "missing_data = eda.analyze_missing_data()\n",
    "if missing_data.empty:\n",
    "    print(\"No missing data found.\")\n",
    "else:\n",
    "    print(missing_data)\n",
    "\n",
    "# Outlier detection\n",
    "print(\"\\n4. OUTLIER DETECTION\")\n",
    "print(\"-\" * 20)\n",
    "outliers = eda.detect_outliers()\n",
    "if not outliers.empty:\n",
    "    print(outliers)\n",
    "else:\n",
    "    print(\"No outliers detected using IQR method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 40)\n",
    "print(\"ADVANCED VISUALIZATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Distribution plots\n",
    "print(\"\\n1. DISTRIBUTION PLOTS\")\n",
    "print(\"-\" * 20)\n",
    "if eda.numeric_columns:\n",
    "    fig1 = eda.plot_distribution(figsize=(15, 10))\n",
    "    plt.show()\n",
    "\n",
    "# Categorical distributions\n",
    "print(\"\\n2. CATEGORICAL DISTRIBUTIONS\")\n",
    "print(\"-\" * 30)\n",
    "if eda.categorical_columns:\n",
    "    fig2 = eda.plot_categorical_distributions(figsize=(15, 8))\n",
    "    plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "print(\"\\n3. CORRELATION MATRIX\")\n",
    "print(\"-\" * 20)\n",
    "if len(eda.numeric_columns) > 1:\n",
    "    fig3 = eda.plot_correlation_matrix(figsize=(12, 10))\n",
    "    plt.show()\n",
    "\n",
    "# Interactive correlation matrix\n",
    "print(\"\\n4. INTERACTIVE CORRELATION MATRIX\")\n",
    "print(\"-\" * 35)\n",
    "if len(eda.numeric_columns) > 1:\n",
    "    interactive_fig = interactive_visualizer.interactive_correlation_matrix()\n",
    "    interactive_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 40)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if target_column in loader.dataset.columns:\n",
    "    # Target distribution\n",
    "    print(\"\\n1. TARGET DISTRIBUTION\")\n",
    "    print(\"-\" * 22)\n",
    "    target_counts = loader.dataset[target_column].value_counts()\n",
    "    print(target_counts)\n",
    "    \n",
    "    # Target distribution plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    target_counts.plot(kind='bar', ax=ax, color='skyblue')\n",
    "    ax.set_title(f'Distribution of {target_column}')\n",
    "    ax.set_xlabel(target_column)\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Relationship analysis\n",
    "    print(\"\\n2. FEATURE-TARGET RELATIONSHIPS\")\n",
    "    print(\"-\" * 32)\n",
    "    relationships = eda.analyze_target_relationships()\n",
    "    \n",
    "    if 'numerical_correlations' in relationships:\n",
    "        print(\"Top numerical feature correlations with target:\")\n",
    "        for feature, stats in relationships['numerical_correlations'].items():\n",
    "            significance = \"significant\" if stats['significant'] else \"not significant\"\n",
    "            print(f\"  {feature}: {stats['correlation']:.3f} ({significance})\")\n",
    "    \n",
    "    if 'categorical_anova' in relationships:\n",
    "        print(\"\\nCategorical feature relationships with target:\")\n",
    "        for feature, stats in relationships['categorical_anova'].items():\n",
    "            significance = \"significant\" if stats['significant'] else \"not significant\"\n",
    "            print(f\"  {feature}: F={stats['f_statistic']:.3f} ({significance})\")\n",
    "    \n",
    "    # Boxplots by target\n",
    "    print(\"\\n3. NUMERICAL FEATURES BY TARGET\")\n",
    "    print(\"-\" * 32)\n",
    "    if len(eda.numeric_columns) > 0:\n",
    "        fig4 = AdvancedVisualizations.plot_boxplots_by_target(\n",
    "            loader.dataset, target_column, eda.numeric_columns[:6], figsize=(15, 10)\n",
    "        )\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"Target column '{target_column}' not found in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 40)\n",
    "print(\"KEY INSIGHTS AND FINDINGS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate EDA report\n",
    "eda_report = eda.generate_eda_report()\n",
    "print(eda_report)\n",
    "\n",
    "# Additional insights\n",
    "print(\"ADDITIONAL INSIGHTS:\")\n",
    "print(\"-\" * 18)\n",
    "\n",
    "if eda.numeric_columns:\n",
    "    print(f\"1. Dataset contains {len(eda.numeric_columns)} numerical features.\")\n",
    "    print(f\"2. Dataset contains {len(eda.categorical_columns)} categorical features.\")\n",
    "    print(f\"3. Total missing values: {loader.dataset.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Highlight strong correlations\n",
    "    if len(eda.numeric_columns) > 1:\n",
    "        corr_matrix = loader.dataset[eda.numeric_columns].corr()\n",
    "        # Find strong correlations (abs > 0.5)\n",
    "        strong_corrs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) > 0.5:\n",
    "                    strong_corrs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))\n",
    "        \n",
    "        if strong_corrs:\n",
    "            print(\"4. Strong correlations found:\")\n",
    "            for var1, var2, corr in strong_corrs[:5]:  # Show top 5\n",
    "                print(f\"   {var1} â†” {var2}: {corr:.3f}\")\n",
    "        else:\n",
    "            print(\"4. No strong correlations (|r| > 0.5) found.\")\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS:\")\n",
    "print(\"-\" * 15)\n",
    "print(\"1. Address missing values in the data cleaning phase.\")\n",
    "print(\"2. Consider feature engineering for highly correlated variables.\")\n",
    "print(\"3. Investigate outliers in detail during data cleaning.\")\n",
    "print(\"4. Use the identified target relationships for model development.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive dashboard\n",
    "print(\"=\" * 40)\n",
    "print(\"INTERACTIVE DASHBOARD\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    dashboard = AdvancedVisualizations.create_eda_dashboard(loader.dataset, target_column)\n",
    "    dashboard.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not create dashboard: {e}\")\n",
    "    print(\"Dashboard creation requires more complex setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 30)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 30)\n",
    "print(\"1. Proceed to data cleaning and preprocessing notebook\")\n",
    "print(\"2. Address identified data quality issues\")\n",
    "print(\"3. Implement feature engineering strategies\")\n",
    "print(\"4. Prepare data for machine learning models\")\n",
    "print(\"5. Document all findings in the final report\")\n",
    "\n",
    "print(\"\\nEDA COMPLETED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
